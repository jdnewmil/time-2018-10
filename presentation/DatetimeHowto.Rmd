---
title: "A Brief Date-Time Howto"
author: "Jeff Newmiller"
date: "October 2, 2018 (updated May 10, 2020)"
output: slidy_presentation
css: "../css/custom.css"
knit: (function(input_file, encoding) {
   out_dir <- 'docs';
   rmarkdown::render( input_file
                    , encoding = encoding
                    , output_file = file.path( dirname(input_file)
                                             , ".."
                                             , out_dir
                                             , 'DatetimeHowto.html'
                                             )
                    )
   })

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.height = 3, fig.width = 7, tidy = TRUE)
suppressPackageStartupMessages( library(dplyr) )
suppressPackageStartupMessages( library(ggplot2) )
suppressPackageStartupMessages( library(lubridate) )
library(DiagrammeR)
```

# Date/Time FAQs

Will show examples of fixing common time-related problems:

- Why do Date/Time values sometimes make messy plots?
- Why are my Date/Time values `NA`?
- Why does R sometimes convert only part of the timestamp?
- How do we handle daylight savings time?
- Time in a series of columns?
- Comparing Dates and Date/Times?

# Example Dataset

Sample residential electric load data from London, England[^5]. Peak energy usage usually occurs around 8pm, depending somewhat on day of week.

```{r introcalc,echo=FALSE}
dta <- read.csv( "../data/MAC000002clean.csv", as.is = TRUE )
Sys.setenv( TZ = "GMT" ) # Data are recorded in GMT
dta$Dtm <- as.POSIXct( dta$DateTime )

Sys.setenv( TZ = "Europe/London" ) # interpret data
d <- as.POSIXlt( dta$Dtm ) # keep list time separate from data frame
dta <- (   dta
       %>% mutate( Hour = d$hour
                 , wday = factor( d$wday
                                , levels = 0:6
                                , labels = c( "Sun", "Mon", "Tue"
                                            , "Wed", "Thu", "Fri"
                                            , "Sat" )
                                )
                 , Dt = as.POSIXct( trunc( d, units = "days" ) )
                 , DTime = as.numeric( Dtm - Dt, units="hours" )
                 )
         )
```

```{r introplot,fig.width=6,fig.height=4,warning=FALSE,echo=FALSE}
ggplot( dta, aes( x = DTime, y = KWH, group = Dt ) ) +
  geom_line( alpha = 0.2 ) +
  facet_wrap( ~wday ) +
  scale_x_continuous( name = "Hour of Day"
                    , breaks = 6*( 0:4 )
                    , limits = c( 0, 24 )
                    )
```

# Q: Date/Time values make messy plots?

Why do the following simple commands make such messy x-axis labeling? And it is slow, too!

```{r faq1Qmessyinit, echo=FALSE}
Sys.setenv( TZ = "" )
```

```{r faq1Qmessy, fig.width=6,fig.height=3}
dta <- read.csv( "../data/MAC000002clean.csv", stringsAsFactors = TRUE )
plot( KWH ~ DateTime, data=dta, pch = "." )
```

# A: Because the x-axis is a factor

In versions of R before 4.0.0 the `read.csv` function by default looked for floating point, integer, or logical types, and anything else is treated like a factor. In R 4.0.0 and after, the default is to import unrecognized columns of data as character strings. Plotting character data directly does not work, so an error "NAs introduced by coercion" would appear.

Factors are labels, like "Male" or "Female". The above plot assigns each record its own label, and then "skips" labels to avoid writing them on top of each other.

# A: Use `Date` or `POSIXct` for date/time values

Timestamp values may look similar to character or factor representations, but they are much more flexible.

```{r faq1Achr}
dta <- read.csv( "../data/MAC000002clean.csv"
#               , as.is=TRUE # avoid auto-convert to factor (unnecessary in R4.0..0)
               )
# Simulate YYYY-mm-ddTHH:MM:SS ISO time format
dta$DateTime <- sub( " ", "T", dta$DateTime )
Sys.setenv( TZ = "US/Pacific" ) # If you forget TZ, this is the likely default for SFBay Area
dta$Dtm <- as.POSIXct( dta$DateTime ) # New column
str( dta )
```

I prefer to make a new column to help troubleshoot the time conversion process.

Note there are ways to find out how to refer to timezones on Wikipedia[^8] and in R[^9].

# A: Use `Date` or `POSIXct` for date/time values

The x-axis breaks are more sensible now:

```{r faq1Achrplot,fig.height=3}
plot( KWH ~ Dtm, data = dta, pch = "." )
```

# Useful Date/Time Data Types in R

```{r usefultypes,echo=FALSE,results='asis'}
oldtz <- Sys.getenv( "TZ" )
Sys.setenv( TZ = "GMT" )
s1 <- capture.output( str( unclass( as.POSIXlt( "2013-03-31 03:30:00" ) ) ) )
s2 <- capture.output( print( unclass( as.Date( "2013-03-31" ) ) ) )
s3 <- capture.output( print( unclass( as.POSIXct( "2013-03-31 03:30:00" ) ) ) )
dtminfo <- data.frame( Item = c( "from chr", "to chr", "implementation", "units" )
                     , `Date` = c( '`as.Date( "2013-03-31" )`'
                                 , '`as.character( Dt )`'
                                 , paste( paste0( "`", s2, "`" ), collapse = "<br/>" )
                                 , 'days since `1970-01-01 GMT`'
                                 )
                     , `POSIXct` = c( '`as.POSIXct( "2013-03-31 03:30:00" )`'
                                    , '`as.character( Dtm )`'
                                  , paste( paste0( "`", s3, "`" ), collapse = "<br/>" )
                                    , 'sec since `1970-01-01 00:00:00 GMT`'
                                    )
                     , POSIXlt = c( '`as.POSIXlt( "2013-03-31 03:30:00" )`'
                                  , '`as.character( Dtm )`'
                                  , paste( paste0( "`", s1, "`" ), collapse = "<br/>" )
                                  , 'separate units for each of 9 elements'
                                  )
                     )

knitr::kable( dtminfo
            , format="html"
            , escape=FALSE
            , col.names = c( "Item", "`Date`", "`POSIXct`", "`POSIXlt`")
            )
Sys.setenv( TZ = oldtz )
```

# Good Practices

Converting formatted strings to `POSIXct`:

* Set TZ before converting!
* Beware of YDM or MDY ordering... they need a format specification

```{r goodpractice1,echo=FALSE,fig.height=3}
mermaid('
sequenceDiagram
  File ->> Character : read.csv(as.is=TRUE)
  Character ->> NA : as.POSIXct("2013-21-03 02:30:00")
  Character ->> POSIXct : as.POSIXct("2013-03-10 14:30:00")
  Character ->> POSIXct : as.POSIXct("3/21/13 2:30pm",format="%m/%d%y %I:%M%p")
')
```

# Q: Only part of timestamp converted? (Table)

The converted `Dtm` column does not seem to have hours and minutes in it:

```{r faq1Apart}
head(dta)
```

# Q: Only part of timestamp converted? (Plot)

Just to confirm this problem, we can plot a few days of `Dtm` versus row position:

```{r faq1Apartplot}
idx <- 1:(48*4) # about 4 days of 1/2 hour data 
qplot( idx, dta$Dtm[ idx ] )
```

R is not correctly guessing what format the data are stored in.

# A?: Only part of timestamp converted? Force Format

Experiment: remove the choice to guess which format to use:

```{r faq1Aforce}
dta$Dtm <- as.POSIXct( dta$DateTime
                     , format = "%Y-%m-%dT%H:%M:%S"
                     )
which( is.na( dta$Dtm ) ) # this may not work on Linux/Mac
dta[ 7105:7106, ]
```

These timestamps correspond to the 2013 "spring-forward" daylight savings time change... technically, they are invalid in this timezone. R chose the "date-only" `"%Y-%m-%d"` format that made no attempt to convert the time information because the "date-only" format suceeded for all values in the input.

# A?: Only part of timestamp converted? Force Format (Tabular)

What does the time look like around the spring-forward records using the forced format?

```{r faq1Aforcefwd,warning=FALSE}
dta[ 7103:7109, ]
```

In `US/Pacific` timezone, 3am is one hour after 1am... what if we plot this?

# A?: Only part of timestamp converted? Force Format (Plot)

```{r faq1Aforcefwdplot,warning=FALSE}
idx <- 7101:7109
qplot( idx, dta$Dtm[ idx ] )
```

But if this is actually how the data were recorded, why the bad data?

# A: Use the `TZ` Environment Variable

Solution is to tell R what the correct timezone is *before* converting from character. This data was from London, and it did not appear to have a "spring-forward" so it doesn't have daylight savings:

```{r faq1Agmt}
Sys.setenv( TZ = "GMT" )
dta$Dtm <- as.POSIXct( dta$DateTime, format = "%Y-%m-%dT%H:%M:%S" )
idx <- 7101:7109
qplot( idx, dta$Dtm[ idx ] )
```

No `NA` values, time increments uniformly! Looking better!

# A: Only part of timestamp converted? (Summary)

* Don't ever let your default timezone control how your data are interpreted! At a minimum invoke `Sys.setenv(TZ=AppropriateTimeZone)` at the beginning of your script.
* R may try to guess what format the data are in (`"%Y-%m-%d"` or `"%Y-%m-%d %H:%M:%S"`), but the number of possibilities that R will *not* try is very large so if at all possible work with data laid out just one way and tell R what way that is (e.g. `as.POSIXct( Dtm, format="%Y-%m-%d %H:%M:%S" )`)

# Q: Why does the data look shifted during summer?

Look at February and April 2013:

```{r faq1Qsummercalc}
# find beginning of day for each record
dta$DBegin <- as.POSIXct( trunc( dta$Dtm, units="days" ) )
# find hours from midnight
dta$DTime <- as.numeric( dta$Dtm - dta$DBegin, units="hours" )
# find timestamp at beginning of month for each record
dta$MBegin <- as.POSIXct( paste0( substr( dta$DateTime, 1, 7 )
                                , "-01" ) )
dta2mo <- subset( dta
                , dta$MBegin
                   %in% as.POSIXct( c( "2013-02-01"
                                     , "2013-04-01" ) ) )
```

# Q: Why does the data look shifted during summer? (Plot)

```{r faq1Qsummerplot,echo=FALSE}
dta2mo$MBeginf <- factor( dta2mo$MBegin )
ggplot( dta2mo, aes( x=DTime, y=KWH, group=DBegin ) ) +
  geom_line( alpha = 0.2 ) +
  facet_wrap( ~MBeginf, ncol=1 )
```

# A: Because the people are following civil time

Even though the data are recorded in GMT, the people using the electricity react to the civil time clock. After converting from character, we can change `TZ` so the same timestamps will display differently when plotted or printed:

```{r faq2Acivilcalc}
Sys.setenv( TZ = "Europe/London" )
# find beginning of day for each record
dta$DBegin <- as.POSIXct( trunc( dta$Dtm, units="days" ) )
# find hours from midnight
dta$DTime <- as.numeric( dta$Dtm - dta$DBegin, units="hours" )
# find timestamp at beginning of month for each record
dta$MBegin <- as.POSIXct( paste0( substr( dta$DateTime, 1, 7 )
                                , "-01" ) )
dta2mo <- subset( dta
                , dta$MBegin
                   %in% as.POSIXct( c( "2013-02-01"
                                     , "2013-04-01" ) ) )
```

# A: Because the people are following civil time (Plot)

```{r faq2Acivilplot,echo=FALSE}
dta2mo$MBeginf <- factor( dta2mo$MBegin )
ggplot( dta2mo, aes( x=DTime, y=KWH, group=DBegin ) ) +
  geom_line( alpha = 0.2 ) +
  facet_wrap( ~MBeginf, ncol=1 )
```

# Q: How to handle multi-column Date/Times?

An old solar weather file for San Francisco Airport [^6]:

These files were recorded in "local standard time" (LST; no daylight savings). Could set TZ="GMT" if desired, but here we illustrate what an LST data set looks like, and show how to convert multiple numeric columns into a timestamp using `ISOdatetime`:

```{r faq3multiread,echo=FALSE}
# download.file( url = "https://rredc.nrel.gov/solar/old_data/nsrdb/1961-1990/hourly/1990/23234_90.txt"
#              , destfile = "../data/23234_90.txt"
#              )
dta3 <- read.fwf( "../data/23234_90.txt", header = FALSE
                , skip = 1, stringsAsFactors = FALSE
                , widths = c( 3, 3, 3, 3, 5, 5, 5, 2, 1, 5
                            , 2, 1, 5, 2, 1 )
                , na.strings = " 9999"
                )
dta3 <- setNames( dta3
                , c( "Yr", "Mo", "Dy", "Hr", "G_etdir", "G_etdni"
                   , "G_g", "G_g_src", "G_g_unc", "G_n", "G_n_src"
                   , "G_n_unc", "G_d", "G_d_src", "G_d_unc"
                   )
                )
```

```{r faq3multistr}
# dta3 import not shown
str( dta3 )
```

# A: How to handle multi-column Date/Times? ISOdatetime

```{r faq3Amulticonvert,warning=FALSE,fig.height=4}
Sys.setenv( TZ = "Etc/GMT+8" ) # yes, that is plus for West of GMT
dta3$Dtm <- with( dta3, ISOdatetime( Yr + 1900, Mo, Dy, Hr, 0, 0 ) )
```

```{r faq3Amultiplot, echo=FALSE,warning=FALSE}
ggplot( dta3, aes( x=Dtm, y=G_g ) ) + geom_line( size=0.2, alpha=0.5 )
```

# Q: Separate Dates and Times

Yet another old source of solar data [^7]:

```{r faq4Qseparate,echo=FALSE}
# download.file( "https://rredc.nrel.gov/solar/old_data/nsrdb/1991-2010/data/hourly/724940/724940_2010_solar.csv"
#              , destfile = "../data/724940_2010_solar.csv"
#              )
dta4 <- read.csv( "../data/724940_2010_solar.csv", check.names = FALSE
                , as.is = TRUE, na.strings = "-9900" )
```

```{r faq4Qseparateshow}
# dta4 import not shown
str( dta4 )
```

# A: Separate Dates and Times

The `Date` type is convenient if you don't need to worry about time, but beware of comparing or calculating between `Date` and `POSIXct`:

```{r faq4Qseparatecalc,warning=FALSE}
Sys.setenv(TZ = "Etc/GMT+8" ) # local standard time only
dta4$Dt <- as.Date( dta4$`YYYY-MM-DD` )
dta4$Dtm <- as.POSIXct( paste( dta4$`YYYY-MM-DD`, dta4$`HH:MM (LST)` ) )
head( dta4[ , c( "YYYY-MM-DD", "HH:MM (LST)", "Dt", "Dtm" ) ] )
dta4$Dtm[ 1 ] - as.POSIXct( dta4$Dt[ 1 ] )
```

When a `Date` value is converted to `POSIXct`, it is *always* treated as if it was in GMT timezone! If you need a midnight-date that can be compared/subtracted with `POSIXct` intuitively then use `as.POSIXct( trunc( Dtm ) )`. Also avoid mixing variables created with `ISOdate` and `ISOdatetime` for the same reason.


# Conclusion

- Use `Date` when none of your data has time-of-day, and `POSIXct` if it has time values.
    + There is no "time-only" data type in R because time can compute differently on different days!
- *Always* set `TZ` before using time functions!
    + If you don't know the correct timezone, you can often get as far as Excel would let you by just pretending it is in "GMT".
- Avoid converting `POSIXct` directly to numeric... it is unnecessary in most cases and makes your time manipulations overly-complicated
    + It is fine to convert `difftime` to and from numeric... just remember to specify the units in both conversion directions
- On Windows, you can use `sum( is.na( Dtm ) )` to check if invalid date/times were present. These may indicate incorrect timezone assumptions (including failure to set `TZ`) if they occur in the daylight-savings-time spring-forward hour. On other OSes you may just have to look closely at transition times.

---
[^5]: https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households
[^6]: *NSRDB 1961-1990: Hourly Data Files*, https://rredc.nrel.gov/solar/old_data/nsrdb/1961-1990/
[^7]: *National Solar Radiation Data Base 1991- 2010 Update*, https://rredc.nrel.gov/solar/old_data/nsrdb/1991-2010/
[^8]: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
[^9]: `?OlsonNames`
